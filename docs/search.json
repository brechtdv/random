[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Confounding\n\n\n\n\n\nIdentifying and addressing confounding in observational data\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\n  \n\n\n\n\nFitting distributions\n\n\n\n\n\nSome useful functions to fit distributions to means, confidence intervals and standard errors\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\n  \n\n\n\n\nSIR model\n\n\n\n\n\nDifferent implementations of the basic SIR model\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am head of the Service Health information at Sciensano, the Belgian institute for health. I am also appointed as visiting professor in Risk Analysis at Ghent University. As a senior epidemiologist, I conduct policy-driven public health research in the domain of composite measures of population health and health inequalities. Currently, I am coordinating the Belgian National Burden of Disease Study, and chairing the European Burden of Disease Network (COST Action CA18218). As a member of the World Health Organization Foodborne Disease Burden Epidemiology Reference Group (WHO/FERG), I am also contributing to the estimation of the global burden of foodborne disease. I have PhD degrees in Public Health and Veterinary Sciences, and MSc degrees in Biostatistics and Veterinary Medicine.\nMy full cv is available via brechtdv.github.io."
  },
  {
    "objectID": "posts/01-fitting-distributions/index.html",
    "href": "posts/01-fitting-distributions/index.html",
    "title": "Fitting distributions",
    "section": "",
    "text": "## function for fitting\nfit_beta <-\nfunction (par, p = 0.95) {\n  target <- par[2:3]\n  p <- c(0, p) + (1 - p)/2\n  f <-\n  function(x, mean, p, target) {\n    dev <- qbeta(p = p, shape1 = x, shape2 = x/mean - x)\n    return(sum((dev - target)^2))\n  }\n  shape1 <-\n    optimize(f, c(0, 1e4), mean = par[1], p = p, target = target)$minimum\n  shape2 <- shape1 / par[1] - shape1\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n## function for simulating from fitted distribution\nsim_beta <-\n  function(n, ...) {\n    fit <- fit_beta(...)\n    return(rbeta(n, fit$shape1, fit$shape2))\n  }\n\n## disability weights for diarrhea\ndw_dia_mld <- c(0.074, 0.049, 0.104)\ndw_dia_mod <- c(0.188, 0.125, 0.264)\ndw_dia_sev <- c(0.247, 0.164, 0.348)\n\n## simulate from fitted Beta distribution\nn <- 1e5\nsim_dw_dia_mld <- sim_beta(n, dw_dia_mld)\nsim_dw_dia_mod <- sim_beta(n, dw_dia_mod)\nsim_dw_dia_sev <- sim_beta(n, dw_dia_sev)\n\n## compare fitted to observed values\nsummarize <-\n  function(x, probs = c(0.025, 0.975), ...) {\n    c(mean = mean(x, ...),\n      quantile(x, probs, ...))\n  }\n\nrbind(observed = dw_dia_mld, fitted = summarize(sim_dw_dia_mld))\n\n               mean      2.5%     97.5%\nobserved 0.07400000 0.0490000 0.1040000\nfitted   0.07404733 0.0487965 0.1038908\n\nrbind(observed = dw_dia_mod, fitted = summarize(sim_dw_dia_mod))\n\n              mean      2.5%     97.5%\nobserved 0.1880000 0.1250000 0.2640000\nfitted   0.1879728 0.1232797 0.2627209\n\nrbind(observed = dw_dia_sev, fitted = summarize(sim_dw_dia_sev))\n\n             mean      2.5%     97.5%\nobserved 0.247000 0.1640000 0.3480000\nfitted   0.246645 0.1597582 0.3448211\n\n## visualize random values\nboxplot(\n  las = 1,\n  ylab = \"Disability Weight\",\n  cbind(\"Mild\" = sim_dw_dia_mld,\n        \"Moderate\" = sim_dw_dia_mod,\n        \"Severe\" = sim_dw_dia_sev))"
  },
  {
    "objectID": "posts/01-fitting-distributions/index.html#heading",
    "href": "posts/01-fitting-distributions/index.html#heading",
    "title": "My Post",
    "section": "Heading",
    "text": "Heading\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19044)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_Belgium.utf8  LC_CTYPE=English_Belgium.utf8   \n[3] LC_MONETARY=English_Belgium.utf8 LC_NUMERIC=C                    \n[5] LC_TIME=English_Belgium.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.29     jsonlite_1.8.0    magrittr_2.0.3    evaluate_0.16    \n [5] rlang_1.0.6       stringi_1.7.8     cli_3.4.1         rstudioapi_0.14  \n [9] rmarkdown_2.16    tools_4.2.1       stringr_1.4.1     htmlwidgets_1.5.4\n[13] xfun_0.32         yaml_2.3.5        fastmap_1.1.0     compiler_4.2.1   \n[17] htmltools_0.5.3   knitr_1.40"
  },
  {
    "objectID": "posts/01-fitting-distributions/index.html#gamma-distribution",
    "href": "posts/01-fitting-distributions/index.html#gamma-distribution",
    "title": "Fitting distributions",
    "section": "Gamma distribution",
    "text": "Gamma distribution\n\n## function for fitting\nfit_gamma <-\nfunction(q, p = 0.95) {\n  p <- c(0, p) + (1 - p)/2\n\n  f <-\n    function(x, p, target) {\n      dev <- qgamma(p = p, shape = x[1], rate = x[2])\n      return(sum((dev - target) ^ 2))\n    }\n\n  fit <- optim(par = c(1, 1), fn = f, p = p, target = q)\n\n  return(fit$par)\n}"
  },
  {
    "objectID": "posts/fitting-distributions/index.html",
    "href": "posts/fitting-distributions/index.html",
    "title": "Fitting distributions",
    "section": "",
    "text": "## function for fitting\nfit_beta <-\nfunction (par, p = 0.95) {\n  target <- par[2:3]\n  p <- c(0, p) + (1 - p)/2\n  f <-\n  function(x, mean, p, target) {\n    dev <- qbeta(p = p, shape1 = x, shape2 = x/mean - x)\n    return(sum((dev - target)^2))\n  }\n  shape1 <-\n    optimize(f, c(0, 1e4), mean = par[1], p = p, target = target)$minimum\n  shape2 <- shape1 / par[1] - shape1\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n## function for simulating from fitted distribution\nsim_beta <-\n  function(n, ...) {\n    fit <- fit_beta(...)\n    return(rbeta(n, fit$shape1, fit$shape2))\n  }\n\n## disability weights for diarrhea\ndw_dia_mld <- c(0.074, 0.049, 0.104)\ndw_dia_mod <- c(0.188, 0.125, 0.264)\ndw_dia_sev <- c(0.247, 0.164, 0.348)\n\n## simulate from fitted Beta distribution\nn <- 1e5\nsim_dw_dia_mld <- sim_beta(n, dw_dia_mld)\nsim_dw_dia_mod <- sim_beta(n, dw_dia_mod)\nsim_dw_dia_sev <- sim_beta(n, dw_dia_sev)\n\n## compare fitted to observed values\nsummarize <-\n  function(x, probs = c(0.025, 0.975), ...) {\n    c(mean = mean(x, ...),\n      quantile(x, probs, ...))\n  }\n\nrbind(observed = dw_dia_mld, fitted = summarize(sim_dw_dia_mld))\n\n               mean       2.5%     97.5%\nobserved 0.07400000 0.04900000 0.1040000\nfitted   0.07403453 0.04881904 0.1040163\n\nrbind(observed = dw_dia_mod, fitted = summarize(sim_dw_dia_mod))\n\n              mean     2.5%     97.5%\nobserved 0.1880000 0.125000 0.2640000\nfitted   0.1880237 0.123059 0.2625791\n\nrbind(observed = dw_dia_sev, fitted = summarize(sim_dw_dia_sev))\n\n             mean      2.5%     97.5%\nobserved 0.247000 0.1640000 0.3480000\nfitted   0.246962 0.1603662 0.3455071\n\n## visualize random values\nboxplot(\n  las = 1,\n  ylab = \"Disability Weight\",\n  cbind(\"Mild\" = sim_dw_dia_mld,\n        \"Moderate\" = sim_dw_dia_mod,\n        \"Severe\" = sim_dw_dia_sev))"
  },
  {
    "objectID": "posts/fitting-distributions/index.html#gamma-distribution",
    "href": "posts/fitting-distributions/index.html#gamma-distribution",
    "title": "Fitting distributions",
    "section": "Gamma distribution",
    "text": "Gamma distribution\n\n## function for fitting\nfit_gamma <-\nfunction(q, p = 0.95) {\n  p <- c(0, p) + (1 - p)/2\n\n  f <-\n    function(x, p, target) {\n      dev <- qgamma(p = p, shape = x[1], rate = x[2])\n      return(sum((dev - target) ^ 2))\n    }\n\n  fit <- optim(par = c(1, 1), fn = f, p = p, target = q)\n\n  return(fit$par)\n}"
  },
  {
    "objectID": "posts/sir-model/index.html",
    "href": "posts/sir-model/index.html",
    "title": "SIR model",
    "section": "",
    "text": "The classical SIR model is a useful example to understand how disease transmission models are constructed. The SIR model defines three states â€” susceptible, infectious, and recovered, and assumes that the only possible transitions are from susceptible to infectious, and from infectious to recovered.\nHere we implement the SIR model using three different approaches, to show the similarities between these approaches."
  },
  {
    "objectID": "posts/sir-model/index.html#parameter-values",
    "href": "posts/sir-model/index.html#parameter-values",
    "title": "SIR model",
    "section": "Parameter values",
    "text": "Parameter values\n\nN &lt;- 8900       # population size\nt &lt;- 20         # time steps\nbeta &lt;- 0.0004  # transmission probability\nalpha &lt;- 0.5    # recovery probability (corresponding to a duration of 1/0.5=2 time steps)"
  },
  {
    "objectID": "posts/sir-model/index.html#set-up-data-frame",
    "href": "posts/sir-model/index.html#set-up-data-frame",
    "title": "SIR model",
    "section": "Set up data frame",
    "text": "Set up data frame\n\npop &lt;-\n  data.frame(\n    DAY = seq(0, t),\n    S = numeric(t+1),\n    I = numeric(t+1),\n    R = numeric(t+1))\npop$S[1] &lt;- N - 1 # there needs to be 1 infectious person to start\npop$I[1] &lt;- 1\npop$R[1] &lt;- 0"
  },
  {
    "objectID": "posts/sir-model/index.html#run-model",
    "href": "posts/sir-model/index.html#run-model",
    "title": "SIR model",
    "section": "Run model",
    "text": "Run model\n\nfor (i in seq(t)) {\n  pop$S[i+1] &lt;-\n    pop$S[i] - pop$S[i] * (1 - (1 - beta)^pop$I[i])\n  pop$I[i+1] &lt;-\n    pop$I[i] + pop$S[i] * (1 - (1 - beta)^pop$I[i]) - pop$I[i] * alpha\n  pop$R[i+1] &lt;-\n    pop$R[i]                                        + pop$I[i] * alpha\n}"
  },
  {
    "objectID": "posts/sir-model/index.html#plot-results",
    "href": "posts/sir-model/index.html#plot-results",
    "title": "SIR model",
    "section": "Plot results",
    "text": "Plot results\n\nmatplot(\n  pop[, -1],\n  type = \"l\",\n  col = c(\"green\", \"red\", \"blue\"),\n  las = 1)"
  },
  {
    "objectID": "posts/sir-model/index.html#settings",
    "href": "posts/sir-model/index.html#settings",
    "title": "SIR model",
    "section": "Settings",
    "text": "Settings\n\n## load deSolve package\nlibrary(deSolve)\n\nWarning: package 'deSolve' was built under R version 4.2.2\n\n## create SIR function\nsir &lt;- function(time, state, parameters) {\n\n  with(as.list(c(state, parameters)), {\n\n    dS &lt;- -beta * S * I\n    dI &lt;-  beta * S * I - alpha * I\n    dR &lt;-                 alpha * I\n\n    return(list(c(dS, dI, dR)))\n  })\n}"
  },
  {
    "objectID": "posts/sir-model/index.html#initialisation",
    "href": "posts/sir-model/index.html#initialisation",
    "title": "SIR model",
    "section": "Initialisation",
    "text": "Initialisation\n\n## proportion in each compartment\ninit &lt;- c(S = 8699/8700, I = 1/8700, R = 0.0)\n\n## beta: infection parameter; alpha: recovery parameter\nparameters &lt;- c(beta = 1.5, alpha = 0.2)\n\n## time frame\ntimes &lt;- seq(0, 20, by = 0.1)"
  },
  {
    "objectID": "posts/sir-model/index.html#solve-using-ode-general-solver-for-ordinary-differential-equations",
    "href": "posts/sir-model/index.html#solve-using-ode-general-solver-for-ordinary-differential-equations",
    "title": "SIR model",
    "section": "Solve using ode (General Solver for Ordinary Differential Equations)",
    "text": "Solve using ode (General Solver for Ordinary Differential Equations)\n\nout &lt;- ode(y = init, times = times, func = sir, parms = parameters)"
  },
  {
    "objectID": "posts/sir-model/index.html#plot-results-1",
    "href": "posts/sir-model/index.html#plot-results-1",
    "title": "SIR model",
    "section": "Plot results",
    "text": "Plot results\n\n## change to data frame\nout &lt;- as.data.frame(out[, -1])\n\n## plot matrix\nmatplot(\n  x = times, y = out, type = \"l\", las = 1,\n  xlab = \"Time\", ylab = \"Proportion of population\", main = \"SIR Model\",\n  lwd = 1, lty = 1, bty = \"l\", col = c(\"green\", \"red\", \"blue\"))\n\n## add legend\nlegend(\n  \"topright\", c(\"Susceptible\", \"Infected\", \"Recovered\"),\n  pch = 1, col = c(\"green\", \"red\", \"blue\"))"
  },
  {
    "objectID": "posts/sir-model/index.html#parameter-values-1",
    "href": "posts/sir-model/index.html#parameter-values-1",
    "title": "SIR model",
    "section": "Parameter values",
    "text": "Parameter values\n\nN &lt;- 8900       # population size\nt &lt;- 20         # iterations\nbeta &lt;- 0.0004  # transmission probability\nalpha &lt;- 0.5    # recovery probability (corresponding to a duration of 1/0.5=2 time steps)"
  },
  {
    "objectID": "posts/sir-model/index.html#set-up-data-frame-1",
    "href": "posts/sir-model/index.html#set-up-data-frame-1",
    "title": "SIR model",
    "section": "Set up data frame",
    "text": "Set up data frame\n\npop &lt;- matrix(nrow = N, ncol = t+1)\npop[, 1] &lt;- c(\"I\", rep(\"S\", N-1))"
  },
  {
    "objectID": "posts/sir-model/index.html#run-model-1",
    "href": "posts/sir-model/index.html#run-model-1",
    "title": "SIR model",
    "section": "Run model",
    "text": "Run model\n\nfor (i in seq(t)) {\n  # identify S/I/R\n  is_S &lt;- pop[, i] == \"S\"\n  is_I &lt;- pop[, i] == \"I\"\n  is_R &lt;- pop[, i] == \"R\"\n\n  # calculate transition probability\n  beta_t &lt;- 1 - (1 - beta)^sum(is_I)\n  \n  # S may become I or stay S\n  pop[is_S, i+1] &lt;-\n    sample(\n      x = c(\"I\", \"S\"),\n      size = sum(is_S),\n      prob = c(beta_t, 1-beta_t),\n      replace = TRUE)\n  \n  # I may become R or stay I\n  pop[is_I, i+1] &lt;-\n    sample(\n      x = c(\"R\", \"I\"),\n      size = sum(is_I),\n      prob = c(alpha, 1-alpha),\n      replace = TRUE)\n  \n  # R stays R\n  pop[is_R, i+1] &lt;- pop[is_R, i]\n}"
  },
  {
    "objectID": "posts/sir-model/index.html#plot",
    "href": "posts/sir-model/index.html#plot",
    "title": "SIR model",
    "section": "Plot",
    "text": "Plot\n\npop_tab &lt;- apply(pop, 2, function(x) table(factor(x, c(\"S\", \"I\", \"R\"))))\nmatplot(\n  t(pop_tab),\n  type = \"l\",\n  col = c(\"green\", \"red\", \"blue\"),\n  las = 1)"
  },
  {
    "objectID": "posts/sir-model/index.html#parameter-values-2",
    "href": "posts/sir-model/index.html#parameter-values-2",
    "title": "SIR model",
    "section": "Parameter values",
    "text": "Parameter values\n\nN &lt;- 8900       # population size\nt &lt;- 20         # iterations\nbeta &lt;- 0.0004  # transmission probability\nalpha &lt;- 0.5    # recovery probability (corresponding to a duration of 1/0.5=2 time steps)"
  },
  {
    "objectID": "posts/sir-model/index.html#set-up-function",
    "href": "posts/sir-model/index.html#set-up-function",
    "title": "SIR model",
    "section": "Set up function",
    "text": "Set up function\n\nrun &lt;-\n  function() {\n    # set up population\n    pop &lt;- matrix(nrow = N, ncol = t+1)\n    pop[, 1] &lt;- c(\"I\", rep(\"S\", N-1))\n    \n    # run chains\n    for (i in seq(t)) {\n      # identify S/I/R\n      is_S &lt;- pop[, i] == \"S\"\n      is_I &lt;- pop[, i] == \"I\"\n      is_R &lt;- pop[, i] == \"R\"\n      \n      # calculate transition probability\n      beta_t &lt;- 1 - (1 - beta)^sum(is_I)\n      \n      # S may become I or stay S\n      pop[is_S, i+1] &lt;-\n        sample(\n          x = c(\"I\", \"S\"),\n          size = sum(is_S),\n          prob = c(beta_t, 1-beta_t),\n          replace = TRUE)\n      \n      # I may become R or stay I\n      pop[is_I, i+1] &lt;-\n        sample(\n          x = c(\"R\", \"I\"),\n          size = sum(is_I),\n          prob = c(alpha, 1-alpha),\n          replace = TRUE)\n      \n      # R stays R\n      pop[is_R, i+1] &lt;- pop[is_R, i]\n    }\n    \n    # summarize results\n    pop_tab &lt;-\n      t(apply(pop, 2, function(x) table(factor(x, c(\"S\", \"I\", \"R\")))))\n    \n    # return results\n    return(pop_tab)\n  }"
  },
  {
    "objectID": "posts/sir-model/index.html#run-model-2",
    "href": "posts/sir-model/index.html#run-model-2",
    "title": "SIR model",
    "section": "Run model",
    "text": "Run model\n\nruns &lt;- replicate(10, run())"
  },
  {
    "objectID": "posts/sir-model/index.html#plot-1",
    "href": "posts/sir-model/index.html#plot-1",
    "title": "SIR model",
    "section": "Plot",
    "text": "Plot\n\nmatplot(\n  runs[, , 1],\n  type = \"l\",\n  col = c(\"green\", \"red\", \"blue\"),\n  las = 1)\nfor (i in seq(2, 10))\n  matplot(\n    runs[, , i],\n    type = \"l\",\n    col = c(\"green\", \"red\", \"blue\"),\n    las = 1,\n    add = TRUE)"
  },
  {
    "objectID": "posts/epi-confounding/index.html",
    "href": "posts/epi-confounding/index.html",
    "title": "Confounding",
    "section": "",
    "text": "To demonstrate confounding in the relationship between coffee consumption and cardiovascular disease (CVD), using tobacco as a confounder, we first generate a dummy dataset with three variables: coffee consumption, CVD status, and tobacco use. We will assume that tobacco use affects both coffee consumption and the likelihood of CVD.\n\n# Settings\nset.seed(123)  # for reproducibility\nn &lt;- 500       # number of iterations\n\n# Generate tobacco use (confounder)\ntobacco &lt;- rbinom(n, 1, 0.4)  # 40% smokers\n\n# Generate coffee consumption based on tobacco use (confounder effect)\n# Smokers are more likely to drink coffee\ncoffee &lt;- rbinom(n, 1, prob = 0.2 + 0.5 * tobacco)  \n\n# Generate CVD based on tobacco use and coffee consumption\n# Tobacco is a stronger predictor of CVD\nCVD &lt;- rbinom(n, 1, prob = 0.1 + 0.3 * tobacco + 0.05 * coffee)\n\n# Create the data frame\ndata &lt;- data.frame(coffee, tobacco, CVD)\n\n# Examine the first few rows of the dataset\nhead(data)\n\n  coffee tobacco CVD\n1      0       0   0\n2      1       1   1\n3      0       0   0\n4      1       1   1\n5      1       1   1\n6      0       0   0"
  },
  {
    "objectID": "posts/epi-confounding/index.html#scatterplot-with-grouping-exposure-vs.-outcome-with-confounder-grouping",
    "href": "posts/epi-confounding/index.html#scatterplot-with-grouping-exposure-vs.-outcome-with-confounder-grouping",
    "title": "Confounding",
    "section": "Scatterplot with Grouping (Exposure vs.Â Outcome with Confounder Grouping)",
    "text": "Scatterplot with Grouping (Exposure vs.Â Outcome with Confounder Grouping)\nA scatterplot or barplot that groups the data by the confounder (tobacco) can visually show the confounding effect. In this case, we can plot the relationship between coffee and CVD, with separate lines or bars for smokers and non-smokers.\n\nlibrary(ggplot2)\n\n# Create a bar plot showing CVD rate by coffee consumption, stratified by tobacco use\nggplot(data, aes(x = factor(coffee), fill = factor(CVD))) +\n  geom_bar(position = \"fill\") +\n  facet_wrap(~ tobacco, labeller = labeller(tobacco = c(\"0\" = \"Non-smokers\", \"1\" = \"Smokers\"))) +\n  labs(x = \"Coffee Consumption\", fill = \"CVD Status\", y = \"Proportion\") +\n  scale_fill_manual(values = c(\"0\" = \"lightblue\", \"1\" = \"red\")) +\n  ggtitle(\"CVD Proportion by Coffee Consumption (Stratified by Tobacco Use)\")\n\n\n\n\nThis plot shows how the relationship between coffee and CVD changes when stratified by tobacco use. If there is confounding, the relationship between coffee and CVD should look different for smokers and non-smokers."
  },
  {
    "objectID": "posts/epi-confounding/index.html#mosaic-plot-cvd-by-coffee-and-tobacco",
    "href": "posts/epi-confounding/index.html#mosaic-plot-cvd-by-coffee-and-tobacco",
    "title": "Confounding",
    "section": "Mosaic Plot (CVD by Coffee and Tobacco)",
    "text": "Mosaic Plot (CVD by Coffee and Tobacco)\nA mosaic plot helps visualize the relationship between two categorical variables (coffee and CVD) while considering a third categorical variable (tobacco). It is a good way to see if the distribution of CVD cases changes with tobacco use.\n\n# Create a mosaic plot to visualize the relationship between coffee, tobacco, and CVD\nmosaicplot(~ coffee + CVD + tobacco, data = data, color = TRUE,\n           main = \"Mosaic Plot of Coffee, CVD, and Tobacco\",\n           xlab = \"Coffee Consumption\", ylab = \"CVD Status\")\n\n\n\n\nThis mosaic plot helps identify if tobacco modifies the association between coffee and CVD. You can see if the size and color pattern of the boxes vary between smokers and non-smokers."
  },
  {
    "objectID": "posts/epi-confounding/index.html#interaction-plot-coffee-cvd-and-tobacco",
    "href": "posts/epi-confounding/index.html#interaction-plot-coffee-cvd-and-tobacco",
    "title": "Confounding",
    "section": "Interaction Plot (Coffee, CVD, and Tobacco)",
    "text": "Interaction Plot (Coffee, CVD, and Tobacco)\nAn interaction plot can help visually assess whether there is an interaction effect between coffee consumption and tobacco use on the likelihood of CVD. It shows the predicted probabilities or the mean CVD rate across different groups.\n\n# Calculate mean CVD rate by coffee and tobacco groups\nmean_cvd &lt;- aggregate(CVD ~ coffee + tobacco, data = data, FUN = mean)\n\n# Interaction plot\nggplot(mean_cvd, aes(x = factor(coffee), y = CVD, color = factor(tobacco), group = tobacco)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(linewidth = 3) +\n  labs(x = \"Coffee Consumption\", y = \"Mean CVD Rate\", color = \"Tobacco Use\") +\n  ggtitle(\"Interaction Plot: Coffee Consumption, Tobacco, and Mean CVD Rate\")\n\nWarning in geom_point(linewidth = 3): Ignoring unknown parameters: `linewidth`\n\n\n\n\n\nThis plot illustrates how the relationship between coffee consumption and CVD varies by tobacco use. If tobacco is a confounder, the slopes for smokers and non-smokers should differ, suggesting that the effect of coffee on CVD is not the same for both groups."
  },
  {
    "objectID": "posts/epi-confounding/index.html#stratification-by-tobacco-use",
    "href": "posts/epi-confounding/index.html#stratification-by-tobacco-use",
    "title": "Confounding",
    "section": "Stratification by tobacco use",
    "text": "Stratification by tobacco use\nWe can stratify the analysis by tobacco use to compare the effect of coffee on CVD within each group (smokers and non-smokers).\n\n# Stratified analysis for non-smokers\nnon_smokers &lt;- subset(data, tobacco == 0)\nstrat_model_ns &lt;- glm(CVD ~ coffee, data = non_smokers, family = \"binomial\")\nsummary(strat_model_ns)\n\n\nCall:\nglm(formula = CVD ~ coffee, family = \"binomial\", data = non_smokers)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -2.2889     0.2237 -10.230   &lt;2e-16 ***\ncoffee        0.3079     0.4385   0.702    0.483    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 196.09  on 304  degrees of freedom\nResidual deviance: 195.62  on 303  degrees of freedom\nAIC: 199.62\n\nNumber of Fisher Scoring iterations: 5\n\n# Stratified analysis for smokers\nsmokers &lt;- subset(data, tobacco == 1)\nstrat_model_sm &lt;- glm(CVD ~ coffee, data = smokers, family = \"binomial\")\nsummary(strat_model_sm)\n\n\nCall:\nglm(formula = CVD ~ coffee, family = \"binomial\", data = smokers)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  -0.6419     0.2763  -2.323   0.0202 *\ncoffee        0.5103     0.3250   1.570   0.1164  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 266.58  on 194  degrees of freedom\nResidual deviance: 264.06  on 193  degrees of freedom\nAIC: 268.06\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "posts/epi-confounding/index.html#regression-adjustment",
    "href": "posts/epi-confounding/index.html#regression-adjustment",
    "title": "Confounding",
    "section": "Regression adjustment",
    "text": "Regression adjustment\nAs done earlier, logistic regression models can adjust for tobacco use. This method is often more convenient than stratification.\n\n# The adjusted model shown earlier adjusts for tobacco use\nsummary(adjusted_model)\n\n\nCall:\nglm(formula = CVD ~ coffee + tobacco, family = \"binomial\", data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -2.3239     0.2057 -11.298  &lt; 2e-16 ***\ncoffee        0.4377     0.2582   1.696     0.09 .  \ntobacco       1.7344     0.2666   6.507 7.68e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 536.85  on 499  degrees of freedom\nResidual deviance: 459.82  on 497  degrees of freedom\nAIC: 465.82\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "posts/epi-confounding/index.html#g-computation",
    "href": "posts/epi-confounding/index.html#g-computation",
    "title": "Confounding",
    "section": "G-computation",
    "text": "G-computation\nG-computation (or the G-formula) is a causal inference method derived from the counterfactual framework, often used to estimate the causal effect of an exposure on an outcome, adjusting for confounders. G-computation models the outcome (e.g., cardiovascular disease, CVD) under different hypothetical scenarios of the exposure (e.g., coffee consumption) and then averages these over the distribution of confounders (e.g., tobacco use).\nThe G-formula provides a direct way to adjust for confounding by estimating the expected outcome for both treated and untreated groups if everyone in the population had the same level of exposure, regardless of their actual exposure.\nSteps for G-Computation:\n\nFit an outcome model: Model the relationship between the confounder (tobacco), the exposure (coffee), and the outcome (CVD).\nPredict counterfactual outcomes: Use the model to predict the probability of CVD for everyone in the dataset assuming two different scenarios:\n\nEveryone drank coffee (coffee = 1).\nNo one drank coffee (coffee = 0).\n\nEstimate the causal effect: Compare the average predicted outcomes under the two scenarios to estimate the causal effect of coffee consumption on CVD.\n\n\n# Fit a logistic regression model for the outcome\noutcome_model &lt;- glm(CVD ~ coffee + tobacco, data = data, family = binomial)\nsummary(outcome_model)\n\n\nCall:\nglm(formula = CVD ~ coffee + tobacco, family = binomial, data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -2.3239     0.2057 -11.298  &lt; 2e-16 ***\ncoffee        0.4377     0.2582   1.696     0.09 .  \ntobacco       1.7344     0.2666   6.507 7.68e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 536.85  on 499  degrees of freedom\nResidual deviance: 459.82  on 497  degrees of freedom\nAIC: 465.82\n\nNumber of Fisher Scoring iterations: 4\n\n# Create a copy of the data with coffee set to 1 (everyone drinks coffee)\ndata_coffee1 &lt;- data\ndata_coffee1$coffee &lt;- 1\n\n# Predict the probability of CVD for everyone if all drank coffee\npred_coffee1 &lt;- predict(outcome_model, newdata = data_coffee1, type = \"response\")\n\n# Create a copy of the data with coffee set to 0 (no one drinks coffee)\ndata_coffee0 &lt;- data\ndata_coffee0$coffee &lt;- 0\n\n# Predict the probability of CVD for everyone if no one drank coffee\npred_coffee0 &lt;- predict(outcome_model, newdata = data_coffee0, type = \"response\")\n\n# Calculate the mean predicted probability of CVD under both scenarios\nmean_pred_coffee1 &lt;- mean(pred_coffee1)\nmean_pred_coffee0 &lt;- mean(pred_coffee0)\n\n# Calculate the average causal effect (risk difference)\ncausal_effect &lt;- mean_pred_coffee1 - mean_pred_coffee0\ncausal_effect\n\n[1] 0.06703175"
  },
  {
    "objectID": "posts/epi-confounding/index.html#correlation-heatmap",
    "href": "posts/epi-confounding/index.html#correlation-heatmap",
    "title": "Confounding",
    "section": "Correlation heatmap",
    "text": "Correlation heatmap\nThe pairwise correlations between the variables can be visualised in a heatmap:\n\nCoffee and Tobacco have a moderate positive correlation, as expected, since smokers are more likely to drink coffee in this simulated dataset.\nTobacco and CVD show a stronger positive correlation, reflecting that smoking increases the risk of cardiovascular disease.\nCoffee and CVD have a weaker positive correlation, which may be confounded by tobacco use.\n\n\n# Load the required package\nlibrary(ggcorrplot)\n\nLoading required package: ggplot2\n\n# Compute the correlation matrix\ncorr_matrix &lt;- cor(data)\n\n# Plot the correlation heatmap\nggcorrplot(\n  corr_matrix, method = \"circle\",\n  lab = TRUE, title = \"Correlation Matrix: Coffee, Tobacco, and CVD\")"
  }
]